{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Propagación hacia atrás"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Nota:La propagacion hacia atras Modifica tas todas las **variables definidas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo de Regresión\n",
    "- $X \\sim N(1.0, 0.1)$\n",
    "- $Ax=10$\n",
    "- $y_(predict)= Ax$\n",
    "- $y_(target) = 10$\n",
    "- Teoricamente el valor esperado de A~10 (aprox., despejando \"A\" de la ecuacion Ax=10, los valores de x tienen una media de 1)\n",
    "- $L2$ función de pérdida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_vals = np.random.normal(loc=1, scale=0.1, size=200) #200 datos con media 1 y desviacion .1\n",
    "\n",
    "y_vals = np.repeat(10., 200) #200 datos con valor 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_data = tf.placeholder(shape = [1], dtype=tf.float32) #placeholder que recibira un dato\n",
    "\n",
    "y_target = tf.placeholder(shape = [1], dtype=tf.float32) #placeholder que recibira un dato\n",
    "                          \n",
    "A = tf.Variable(tf.random_normal(shape=[1])) #A se inicializa con un valor aleatorio que tiene que converger al valor teorico (10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_pred = tf.mul(A, x_data) #y_predict (ecuacion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.square(my_pred - y_target) #Funcion de perdida (L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Propagacion hacia atras\n",
    "\n",
    "my_optim = tf.train.GradientDescentOptimizer(learning_rate=0.025)\n",
    "\n",
    "train_step = my_optim.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init = tf.initialize_all_variables()\n",
    "\n",
    "session.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paso #20 A = [7.0586925] Loss: [13.649372]\n",
      "Paso #40 A = [8.855332] Loss: [2.4996314]\n",
      "Paso #60 A = [9.537446] Loss: [2.6062286]\n",
      "Paso #80 A = [9.8392515] Loss: [0.09430064]\n",
      "Paso #100 A = [10.128358] Loss: [0.33023664]\n",
      "Paso #120 A = [10.13923] Loss: [0.16395372]\n",
      "Paso #140 A = [10.03006] Loss: [3.0197487]\n",
      "Paso #160 A = [10.017519] Loss: [0.00966682]\n",
      "Paso #180 A = [9.760483] Loss: [0.5917058]\n",
      "Paso #200 A = [10.022392] Loss: [1.6786262]\n"
     ]
    }
   ],
   "source": [
    "for i in range(200):\n",
    "    rand_index = np.random.choice(200) #indexes de 200 datos aleatorios\n",
    "    rand_x = [x_vals[rand_index]]\n",
    "    rand_y = [y_vals[rand_index]]\n",
    "    session.run(train_step, feed_dict={x_data : rand_x, y_target : rand_y})\n",
    "    if (i+1)%20==0:\n",
    "        print(\"Paso #\"+str(i+1)+\" A = \"+str(session.run(A)) + \n",
    "              \" Loss: \"+str(session.run(loss, feed_dict={x_data:rand_x, y_target: rand_y})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo de clasificación binaria\n",
    "- $X_1\\sim N(-2, 1), X_2 \\sim N(2,1)$\n",
    "- $target(X_1) = 0, target(X_2) = 1$\n",
    "- sigmoid(x+A) = $\\frac{1}{1+e^{-(x+A)}}$\n",
    "- Determinar el valor de $A$\n",
    "- Teóricamente $A\\simeq \\frac{m_1+m_2}{2}\\simeq0, m_1 = -2, m_2 = 2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()\n",
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_vals = np.concatenate((np.random.normal(-2,1,100), np.random.normal(2,1,100))) #(100 datos con media -2 y desviacion 1),(100 datos con media 2 y desviacion 1)\n",
    "y_vals = np.concatenate((np.repeat(0., 100), np.repeat(1., 100))) #(100 ceros),(100 unos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_data = tf.placeholder(shape = [1], dtype = tf.float32)\n",
    "y_target = tf.placeholder(shape = [1], dtype = tf.float32)\n",
    "A = tf.Variable(tf.random_normal(mean = 10, shape=[1])) #A se inicializa con una valor lejano a 0, en este caso valor con media 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_prediction = tf.add(x_data, A) #Funcion Sigmoidal (ecuacion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' Como la funcion de perdida para este caso espera conjunto de datos,a la prediccion se le expanden las dimensiones\n",
    "    en este caso se le agrega un 0 para que sean 2 valores '''\n",
    "\n",
    "my_prediction_expanded = tf.expand_dims(my_prediction, 0)\n",
    "\n",
    "y_target_expanded = tf.expand_dims(y_target,0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11.573736]\n"
     ]
    }
   ],
   "source": [
    "init = tf.initialize_all_variables()\n",
    "session.run(init)\n",
    "print(session.run(A)) #Valor inicial de A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cross_Entrpoy (Funcion de perdida)\n",
    "xentr = tf.nn.sigmoid_cross_entropy_with_logits(logits=my_prediction_expanded, labels=y_target_expanded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_optim = tf.train.GradientDescentOptimizer(learning_rate=0.04)\n",
    "\n",
    "train_step = my_optim.minimize(xentr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paso #100, A = [9.534668], Loss = [[8.301673]]\n",
      "Paso #200, A = [7.381938], Loss = [[8.732018e-05]]\n",
      "Paso #300, A = [5.131879], Loss = [[2.5106833]]\n",
      "Paso #400, A = [3.5860605], Loss = [[1.1160958]]\n",
      "Paso #500, A = [2.2933118], Loss = [[0.9777382]]\n",
      "Paso #600, A = [1.4653158], Loss = [[0.82919854]]\n",
      "Paso #700, A = [0.9389965], Loss = [[0.49024102]]\n",
      "Paso #800, A = [0.5729975], Loss = [[0.24175307]]\n",
      "Paso #900, A = [0.4099821], Loss = [[0.19668907]]\n",
      "Paso #1000, A = [0.23640594], Loss = [[0.14279348]]\n",
      "Paso #1100, A = [0.06687311], Loss = [[0.13006996]]\n",
      "Paso #1200, A = [0.02735932], Loss = [[0.04944231]]\n",
      "Paso #1300, A = [0.00879424], Loss = [[0.13113277]]\n",
      "Paso #1400, A = [-0.03630713], Loss = [[0.1877375]]\n",
      "Paso #1500, A = [-0.11860158], Loss = [[0.17975804]]\n",
      "Paso #1600, A = [-0.03481134], Loss = [[0.29201764]]\n",
      "Paso #1700, A = [-0.04983479], Loss = [[0.24386026]]\n",
      "Paso #1800, A = [-0.03123], Loss = [[0.03610916]]\n",
      "Paso #1900, A = [0.00382707], Loss = [[0.06838638]]\n",
      "Paso #2000, A = [-0.03036114], Loss = [[0.3174209]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(2000):\n",
    "    rand_idx = np.random.choice(200)\n",
    "    rand_x = [x_vals[rand_idx]]\n",
    "    rand_y = [y_vals[rand_idx]]\n",
    "    session.run(train_step, feed_dict={x_data : rand_x, y_target : rand_y})\n",
    "    if (i+1)%100==0:\n",
    "        print(\"Paso #\"+str(i+1)+\", A = \"+str(session.run(A))+\", Loss = \"+\n",
    "             str(session.run(xentr, feed_dict={x_data : rand_x, y_target: rand_y})))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
